\documentclass{sigplanconf}
\usepackage{amsmath}
\usepackage{fancyvrb}
\usepackage{url}


\begin{document}

\special{papersize=8.5in,11in}
\setlength{\pdfpageheight}{\paperheight}
\setlength{\pdfpagewidth}{\paperwidth}

\conferenceinfo{CONF 'yy}{Month d--d, 20yy, City, ST, Country} 
\copyrightyear{2015} 
\copyrightdata{978-1-nnnn-nnnn-n/yy/mm} 
\doi{nnnnnnn.nnnnnnn}


\title{Title Text}

\authorinfo{Iavor S. Diatchki}
           {Galois Inc.}
           {iavor.diatchki@gmail.com}

\maketitle

\begin{abstract}
We present a technique for integrating GHC's type-checker with the
functionality provided by an SMT solver.  The technique was developed
to add support for reasoning about type-level functions on natural
numbers, and so our implementation mainly uses the theory of linear
arithmetic.  The technique, however, is more general and makes it
possible to experiment with other external decision procedures.
\end{abstract}

\category{CR-number}{subcategory}{third-level}

\section{Introduction}

For a few years now, there has been a steady push in the Haskell
community to explore and extend the type system, slowly approximating
functionality available in dependently typed languages
\cite{Eisenberg2012,Lindley2013,Eisenberg2014}.  The additional
expressiveness enables Haskell programmers to express more
invariants at compile time, which makes it easier to develop
reliable software, and also makes Haskell a nice language
for embedding domain specific languages \cite{ivory-experience}.
The Haskell compiler is not just a translator, but it also
serves as a tool that analyzes the program, and helps
finds common mistakes early in the development cycle.

Unfortunately, the extra expressiveness comes at a cost:
Haskell's type system is by no means simple. Writing
programs that make use of invariants encoded in the
type system can be complex and time consuming.  For
example, often one spends a lot of time proving simple theorems
about arithmetic which, while important to convince the compiler
that various invariants are preserved, contribute little to
the clarity of the algorithm being implemented \cite{Lindley2013}.

Given that in many cases the proofs constructed by the programmers
tend to be fairly simple, we can't help but wonder if there might
be a away to automate them away, thus gaining the benefits of
static checking, but without cluttering the program with trivial
facts about, say, arithmetic.  This paper presents a technique
to help with this problem: we show one method of integrating
an SMT solver with GHC's type checker.  While we present
the technique in the context of Haskell and GHC, the technique
should be applicable to other programming languages and compilers too.

XXX: Structure of the paper


\section {SMT Solvers}

This Section contains an introduction to the core functionality
of a typical SMT solver, and may be skipped by readers who are already
familiar with similar tools.

SMT solvers, such as CVC4 \cite{cvc4}, Yices \cite{yices}, and Z3
\cite{z3}, implement a wide collection of decision procedures that
work together to solve a common problem.  They have proved to be a useful
tool in both software and hardware verification.
From a user's perspective, the core functionality of an SMT solver is fairly
simple: we may declare uninterpreted constants, assert formulas,
and check if the asserted formulas are {\em satisfiable}.  Checking
for satisfiability simply means that we are asking the
question: are there concrete values for the uninterpreted constants
that make all asserted formulas true.  Here is an example, using
the notation of the SMTLIB standard \cite{smtlib2}

\begin{Verbatim}
(declare-fun x () Int)
(assert (>= x 0))
(assert (= (+ 3 x) 8))
(check-sat)
\end{Verbatim}

The example declares an integer constant, $x$, asserts some formulas---%
using a prefix notation---%
about it, and then asks the solver if the asserted formulas are
satisfiable.  In this case, the answer is affirmative, as choosing
$5$ for $x$ will make all formulas true.  Indeed, if an
SMT solver reports that a set of formulas is satisfiable, typically
it will also provide a {\em satisfying assignment}, which maps
the uninterpreted constants to concrete values that make the
formulas true.

The same machinery may also be used to prove the validity of
a universally quantified formula. The idea is that we use the SMT solver
to look for a {\em counter-example} to the formula, and if on such
example exists, then we can conclude the formula is valid.
For example, if we want to prove that $\forall x. (3 + x = 8) \implies x = 5$,
then we can use the SMT solver to try to find some $x$ that contradicts it:

\begin{Verbatim}
(declare-fun x () Int)
(assert (= 3 x) 8)
(assert (not (= x 5)))
(check-sat)
\end{Verbatim}

To invalidate an implication, we need to assume the premise, and try to
invalidate the conclusion, which is why the second assertion is negated.
In this case the SMT solver tells us that the asserted formulas are not
satisfiable, which means that there are no counter examples to the original
formula and, therefore, it must be valid.


\section{GHC's Constraint Solver}
\label{GHC}

In this Section, we present relevant aspects of GHC's constraint solver.
The full details of the algorithm \cite{outsidein} are beyond the scope
of this paper.

\subsection{Implication Constraints}
During type inference, GHC uses {\em implication constraints}, which do
not appear in Haskell source code directly. An implication constraint is,
roughly, of the form $G\implies W$, where $W$ is a collection
of constraints that need to be discharged, and $G$ are assumptions that
may be used while discharging $W$.  In the GHC source code, the constraints
in $G$ are referred to as {\em given constraints}, while the ones in $W$ are
known as {\em wanted constraints}.  The intuition behind an implication
constraint is that $W$ contains the constraints that were collected
while checking a program fragment, while $G$ contains local assumptions
that are available only in this particular piece of code.  For example,
consider the following program fragment, which uses a GADT:
\begin{Verbatim}
data E :: * -> * where
  EInt :: Int -> E Int

isZero :: E a -> Bool
isZero (EInt x) = x == 0
\end{Verbatim}
When we check the definition of \Verb"isZero", we end up with an implication
constraint like this:
\begin{Verbatim}
(a ~ Int) => (Num a, Eq a)
\end{Verbatim}
Here, \Verb"a" is the type of the pattern variable \Verb"x", the wanted
constraints arise from the use of \Verb"0" and \Verb"(==)" respectively,
and the given constraint is obtain by pattern matching with \Verb"EInt".


\subsection{The Constraint Solver State}
Implication constraints are solved by two calls to the constraint solver:
the first call processes (i.e., assumes) the given constraints, and the
second one processes the wanted constraints.

The constraint solver has two central pieces of state: the {\em work queue},
and the {\em inert set}.  The work queue contains constraints that need to be
processed, while the inert set contains constraints that have already
been processed.  Constraints are removed---one at a time---from the work queue,
and {\em interacted} with the solver's state.  In the process of interaction
we may solve a wanted constraint, possibly adding new constraints to the
work queue, or notice that a constraint is impossible to solve and record
an error, or---if nothing interesting happens---we add the constraint
to the inert set.  It is also possible that during interaction a previously
inert constraint may be reactivated in a rewritten form and re-inserted
in the work queue.  A single invocation of the constraint solver keeps
interacting constraints until the work queue is empty and all constraints
are in the inert set.

\subsection{Type-Checker Plugins}
Integrating an SMT solver with GHC's type-checker is not the only extension
one might want to have---indeed, there is existing work that extends GHC
with support for units of measure \cite{units-of-measure}.  Instead of
having many ad-hoc extensions directly in GHC's constraint solver, we
collaborated to define and implement and API for extending GHC's functionality
via {\em type-checker plug-ins}.  At present, we are aware of two main
users of this API---our work, and the work on units of measure, but we
hope that this mechanism would make it easier for researcher to experiment
with various extensions to GHC's constraint solver.

An interesting question about type-checker plug-ins is: at what point in
GHC's type checker should we hook them in? We considered a few alternatives:
\begin{enumerate}
\item Add a pass to the solver's pipeline, meaning that plug-ins have to
work with constraints one at a time.
\item Add a call to the plug-ins after the constraints solver has reached
an inert state.
\item Hand off implication constraints directly to the plug-ins,
before invoking GHC's constraint solver.
\end{enumerate}

At the end, we decided on option 2.  Option 3 is the most general, as it
would allow for the plug-in to completely override GHC's behavior.  However,
we were more interested in {\em extending} GHC's capabilities rather than
{\em replacing} them, so we opted against it.  Option 1, on the other hand,
has the closest integration with GHC, but since plug-ins need to precess
constraints one at a time, then they often ended up needing some state,
which than had to be stored and managed somewhere, which became rather
complicated.

We chose option 2 as a nice middle ground, which allows us to look at
all constraints at once, but plug-ins can assume that standard stuff
the GHC knows about has already been eliminated. So, after the constraint
solver reaches an inert state, it calls into the plug-ins, which examine
the inert state and attempt to make progress.  If they do, then the
constraint solver is restarted and process repeats.

\subsection{Improvement and Derived Constraints}
An improving substitution \cite{improvement} allows us to instantiate variables
in the constraints with types, potentially enabling further constraint
simplification.  Of course, we should only do so, as long
as we preserve soundness and completeness.  In this context preserving
soundness means that the new constraints should imply the original
constraints (i.e., we didn't just drop some constraints),
while completeness means that the original constraints imply the new ones
(i.e., we didn't loose generality by making arbitrary assumptions).

In GHC, improvement happens when we rewrite constraints using
{\em equality constraints}. There are three sources of equality constraints:
\begin{itemize}
\item {\em given equalities} are implied by the given constraints,
\item {\em wanted equalities} arise when solving wanted constraints,
\item {\em derived equalities} are implied by the given and wanted constraints,
together.
\end{itemize}

The provenance of an equality constraint determines the kinds of
improvements that we can use it for.  Given equalities have solid proof,
and so we may use congruence to rewrite any other constraint.
On the other hand, wanted constraints are goals that need to be proved,
so they {\em cannot} be used to rewrite given constraints.  We may still
use them to rewrite other wanted or derived constraints though.
Finally, derived equalities are implied by the given and wanted constraints
jointly, so they may not be used to rewrite given or wanted constraints
directly, as doing so may lead to circular reasoning.

Instead, derived equalities help with type inference, by guiding the
instantiation of {\em unification variables} with types. In general,
it is always sound to instantiate a unification variable with whatever
type we want: doing so may reject valid programs, but it will not accept
invalid ones, because we still need to solve all necessary constraints.
Of course, we don't want to reject valid programs, and this is where derived
equalities help us: since they are implied by the goals and assumptions
together, we know that we are not loosing any generality when instantiating
as suggested by a derived constraint.  So, for example, if we compute a
derived constraint \Verb"x ~ Int", and we have a wanted constraint
\Verb"Eq x", and \Verb"x" is a unification variable, then we may
rewrite \Verb"Eq x" to \Verb"Eq Int", which we would proceed to solve
as usual.

\section{Integrating GHC with an SMT Solver}

We describe the algorithm in the context of the theory of linear arithmetic
over natural numbers, as having a concrete theory makes it easier to explain
the process and illustrate it with examples.  In the next Section,
we discuss how, and why, we might want to consider other theories also.

\paragraph{Input.} Currently, the algorithm is implemented as a type-checker
plug-in, and so the input to the algorithm is a collection of constraints
that GHC has determine to be inert: GHC simplified everything as much
as it could, improved using equalities, and basically cannot see anything
else to do.  The inert constraints are presented to the plug-in in three
collections, based on the constraints' provenance: one group contains
the given constraints (i.e., assumption), one group contains derived
constraints (see Section~\ref{GHC} for details), and one group contains
the wanted constraints, which are the goals that need solving.

\paragraph{Output.} The desired output of the algorithm is as follows:
\begin{itemize}
  \item Solve as many wanted constraints as possible.
  \item Notice if the wanted constraints are inconsistent.
  \item Compute new given and derived equalities to help solve constraints
        that are outside this decision procedure's scope.
\end{itemize}
The first bullet is clearly the main purpose of the algorithm, but the other
two are quite important also.

The second bullet is useful because it helps us avoid inferring type
schemes with unsatisfiable constraints.  Suppose, for example, that
we had just a single wanted constraint: \Verb"(x + 5) ~ 2".  Since we
are working with natural numbers, this constraint has no solution, so
we will not be able to solve it. As a result, we may end up inferring
a type like this:
\begin{Verbatim}
someFun :: forall x. (x + 5) ~ 2 => ...
\end{Verbatim}
While, technically, this is not wrong, it is undesirable because the type
error is clearly in the definition of \Verb"someFun", but we would delay
reporting the error until the function is called.  So, it is better if
we noticed that the wanted constraints are not satisfiable, are report
and error immediately.

The importance of the third bullet is that it enables collaboration between
the SMT solver plug-in, and the rest of GHC (i.e., the main constraint solver,
and also other plug-ins).  For example, consider an implication constraint
of the form:
\begin{Verbatim}
forall x. (x + 5) ~ 8  =>  KnownNat x
\end{Verbatim}
In this case, we'd have to use the SMT solver to compute a new given
equality, \Verb"x ~ 3".  This equality will then be used by GHC to
rewrite the wanted constraint \Verb"KnownNat x" to \Verb"KnownNat 3",
which in turn can be discharged by the custom solver for the \Verb"KnownNat"
class.  This ``collaboration'' between different solvers is quite common
in GHC.
We discuss this observation further in Section~\ref{modular-typechecker}.


\subsection{Identifying Relevant Constraints}
Our first task is to identify constraints that are relevant to our solver.
In the current implementation, we consider equalities and inequalities
between a subset of the types of kind \Verb"Nat".   The kind \Verb"Nat" is
inhabited by an infinite family of type-constants:
\begin{Verbatim}
0, 1, 2, .. :: Nat
\end{Verbatim}
These constants may be combined and compared using the following
type-level functions:
\begin{Verbatim}
type family (+)   :: Nat -> Nat -> Nat
type family (*)   :: Nat -> Nat -> Nat
type family (<=?) :: Nat -> Nat -> Bool
\end{Verbatim}
These functions have no user-specified definitions: instead, we extended
the core GHC simplifier with support for forward evaluation on concrete
values, so it will evaluate concrete expressions, such as \Verb"2 + 3".
This simple forward evaluation simplifies and cleans up the constraints,
leaving the more complex reasoning involving variables to the algorithm
being presently described.

The declaration for \Verb"(<=?)" refers to the kind \Verb"Bool", which
is simply the lifted \Verb"Bool" type.  As expected, it is inhabited by the
empty types \Verb"True" and \Verb"False".

So the language of interest to us it constraints formed with the two
predicate symbols, \Verb"(~)" and \Verb"(<=?)", and types made out
of variables, natural number constants, and the operations \Verb"(+)" and
\Verb"(*)".  Furthermore, since we are restricted to working with {\em linear}
arithmetic, we only consider multiplication by a constant.

Of course, constraints may contain other symbols too.  For example,
programmers are free to define their own type functions that return
results of kind \Verb"Nat", so it is entirely possible to encounter
constraints like \Verb"(F 3 + 4) ~ 7", where \Verb"F" is some programmer-defined
type-family.

The process of identifying relevant constraints proceeds as follows:
\begin{enumerate}
\item Eliminate constraints that do not have a relevant top-level predicate
symbol.  The relevant predicate symbols are \Verb"(<=?)", and \Verb"(~)" when
used at kind \Verb"Nat".
\item Import the parameters to the predicates guided by the kind:
  \begin{itemize}
  \item The two supported kinds are \Verb"Nat" and \Verb"Bool"
  \item Currently, there are no interesting operations at kind \Verb"Bool"
  \item If we encounter a type outside of our theory, we name it, and replace
        it with a temporary variable.
  \item We remember the name assignments, so that if the same ``foreign'' type
        appears multiple times, it will get the same name.
  \end{itemize}
\end{enumerate}

The step of naming foreign types is similar to the flattening step performed
by GHC's constraint solver, the main difference being that GHC names every
call to a type-function, while we name only terms outside of the theory.
Still, this duplication of work is somewhat unsatisfactory, and it would
be nice to extend GHC's flattening pass so that it can be reused by
external plug-ins.








\subsection{Consistency and Improvement}

\subsection{Simplifying Constraints}



Given an implication constraint: $G\implies W$.
\begin{enumerate}
\item Identify constraints in the theory
\item Name sub-terms that are outside the theory
\item Assume $G$
\item Check for satisfiability
  \begin{itemize}
  \item If unsat, implication is trivial, record error
  \item If sat, use model for improvement
  \end{itemize}
\item ...
\end{enumerate}


\section{Other Theories}

\paragraph{Integers.}
\paragraph{Boolean.}  SAT solver in the type system
\paragraph{Bit-vectors.}  Aribtrary modulo arithmeitc; finite sets of effects.
\paragraph{Sets.}


\section{A Modular Constraint Solver}
\label{modular-typechecker}

Relation between type-checker and
the Nelson-Oppen method for combining
decision procedures.


\section {Conclusions}



\bibliographystyle{abbrvnat}
\bibliography{refs}




% 
% % The bibliography should be embedded for final submission.
% 
% \begin{thebibliography}{}
% \softraggedright
% 
% \bibitem[Smith et~al.(2009)Smith, Jones]{smith02}
% P. Q. Smith, and X. Y. Jones. ...reference text...
% 
% \end{thebibliography}


\end{document}

